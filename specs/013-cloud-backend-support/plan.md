# Implementation Plan: Cloud Backend Support with Nexus-Transparent Protocol

**Branch**: `013-cloud-backend-support` | **Date**: 2024-02-11 | **Spec**: [specs/013-cloud-backend-support/spec.md](spec.md)
**Input**: Feature specification from `/specs/013-cloud-backend-support/spec.md`

**Note**: This plan is generated by the speckit.plan workflow. It defines the architecture, research requirements, and data model for F12.

## Summary

Enable Nexus to register and route requests to cloud LLM providers (OpenAI, Anthropic, Google AI) alongside existing local inference backends. Implement the Nexus-Transparent Protocol using X-Nexus-* response headers to expose routing decisions, backend classification, privacy zones, and cost estimates without modifying OpenAI-compatible JSON response bodies. Support bidirectional API format translation for Anthropic and Google while maintaining strict OpenAI compatibility for clients.

## Technical Context

**Language/Version**: Rust 1.87 (stable)  
**Primary Dependencies**: 
- Axum 0.7 (HTTP framework with streaming support)
- Tokio 1.x (async runtime)
- reqwest 0.12 (HTTP client with streaming and connection pooling)
- serde_json 1.x (JSON serialization)
- async-trait 0.1 (trait async methods)
- tiktoken-rs (NEEDS CLARIFICATION - for OpenAI token counting, must verify availability)

**Storage**: In-memory only (DashMap for concurrent backend registry)  
**Testing**: cargo test (unit + integration), wiremock/mockito (HTTP mocking), proptest (property-based)  
**Target Platform**: Linux/macOS/Windows (cross-platform binary)  
**Project Type**: Single binary (library + CLI application)

**Performance Goals**:
- Routing decision: < 1ms (constitution mandate)
- Header injection overhead: < 0.1ms
- Total proxy overhead: < 5ms (constitution mandate)
- Token counting: < 0.5ms for typical requests
- Format translation: < 2ms per request

**Constraints**:
- Zero modifications to response JSON body (OpenAI compatibility)
- Headers-only transparency protocol
- API key security: environment variables only, never in config files
- No breaking changes to existing 468+ tests
- TDD required (constitution mandate)

**Scale/Scope**:
- 3 cloud providers (OpenAI, Anthropic, Google AI)
- 5 new X-Nexus-* headers
- 2 new InferenceAgent implementations (Anthropic, Google - OpenAI already exists)
- Extend 3 existing modules: agent/factory.rs, config/backend.rs, api/completions.rs

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### Simplicity Gate
- [x] Using ≤3 main modules for initial implementation? **YES** - Extending 3 existing modules: agent/, config/, api/
- [x] No speculative "might need" features? **YES** - Only implements spec requirements (P1-P3 user stories)
- [x] No premature optimization? **YES** - Straightforward HTTP proxy pattern, optimize only if profiling shows issues
- [x] Start with simplest approach that could work? **YES** - Reuse existing OpenAIAgent pattern, extend with translation layer for Anthropic/Google

### Anti-Abstraction Gate
- [x] Using Axum/Tokio/reqwest directly (no wrapper layers)? **YES** - Direct use of existing HTTP stack
- [x] Single representation for each data type? **YES** - BackendConfig extended with zone/tier, no parallel structures
- [x] No "framework on top of framework" patterns? **YES** - Standard trait implementation (InferenceAgent)
- [x] Abstractions justified by actual (not theoretical) needs? **YES** - InferenceAgent trait already exists for backend polymorphism

### Integration-First Gate
- [x] API contracts defined before implementation? **YES** - Phase 1 generates contracts/ with OpenAI ↔ Anthropic/Google schemas
- [x] Integration tests planned with real/mock backends? **YES** - wiremock for cloud API mocks, existing test patterns
- [x] End-to-end flow testable? **YES** - Request → Router → CloudAgent → Translation → Headers → Response

### Performance Gate
- [x] Routing decision target: < 1ms? **YES** - No additional routing logic, privacy zone already in AgentProfile
- [x] Total overhead target: < 5ms? **YES** - Header injection < 0.1ms, format translation < 2ms, token counting < 0.5ms
- [x] Memory baseline target: < 50MB? **YES** - Cloud agents add ~5KB each, no persistent state

**Result**: All gates PASS. No violations to justify.

## Project Structure

### Documentation (this feature)

```text
specs/013-cloud-backend-support/
├── spec.md              # Feature specification (input)
├── plan.md              # This file (Phase 0-1 output)
├── research.md          # Phase 0 output (decisions on unknowns)
├── data-model.md        # Phase 1 output (entities and relationships)
├── quickstart.md        # Phase 1 output (developer guide)
├── contracts/           # Phase 1 output (API format examples)
│   ├── openai-chat.json         # OpenAI chat completion format (reference)
│   ├── anthropic-messages.json  # Anthropic Messages API format
│   ├── google-generateContent.json  # Google AI generateContent format
│   └── nexus-headers.http       # X-Nexus-* header specifications
└── tasks.md             # Phase 2 output (NOT created by plan workflow)
```

### Source Code (repository root)

```text
src/
├── agent/
│   ├── mod.rs           # InferenceAgent trait (existing - extends profile)
│   ├── factory.rs       # Agent factory (EXTEND - add Anthropic/Google cases)
│   ├── openai.rs        # OpenAIAgent (existing - already complete)
│   ├── anthropic.rs     # NEW - AnthropicAgent with format translation
│   ├── google.rs        # NEW - GoogleAIAgent with format translation
│   └── types.rs         # AgentProfile/PrivacyZone (existing - add cost fields)
│
├── config/
│   ├── backend.rs       # BackendConfig (EXTEND - add zone/tier fields)
│   └── mod.rs           # Config loading (existing - no changes)
│
├── api/
│   ├── completions.rs   # Response handler (EXTEND - inject X-Nexus-* headers)
│   ├── error.rs         # ApiError (EXTEND - add 503 context object)
│   └── types.rs         # Request/Response types (existing - no changes)
│
├── routing/
│   ├── mod.rs           # RoutingResult (EXTEND - add cost_estimated field)
│   └── requirements.rs  # Request filtering (existing - privacy zone already works)
│
└── lib.rs               # Public API (existing - no changes)

tests/
├── integration/
│   ├── cloud_backends_test.rs    # NEW - cloud backend registration & routing
│   ├── transparent_protocol_test.rs  # NEW - X-Nexus-* header verification
│   ├── format_translation_test.rs    # NEW - Anthropic/Google translation
│   └── actionable_errors_test.rs     # NEW - 503 response structure
│
├── contract/
│   ├── openai_compatibility_test.rs  # NEW - response body unchanged
│   └── streaming_translation_test.rs # NEW - SSE format translation
│
└── unit/
    ├── agent/
    │   ├── anthropic_translation_test.rs  # NEW - message format conversion
    │   └── google_translation_test.rs     # NEW - request/response mapping
    └── api/
        └── headers_injection_test.rs      # NEW - header construction logic
```

**Structure Decision**: Single project (Option 1) - Nexus is a unified binary. All cloud backend support integrates into existing modules using the InferenceAgent abstraction. New agent implementations (Anthropic, Google) follow the established pattern from OpenAIAgent. Tests follow existing hierarchy: contract tests verify OpenAI compatibility, integration tests validate end-to-end flows with mocked cloud APIs, unit tests cover translation logic.

## Complexity Tracking

> **Fill ONLY if Constitution Check has violations that must be justified**

**No violations detected.** All constitution gates pass without exceptions. This feature extends existing patterns (InferenceAgent trait, factory pattern, header injection) without introducing new complexity layers.

---

## Phase 0: Research & Unknowns

### Research Questions

The following technical unknowns must be resolved before Phase 1 design:

#### RQ-001: Token Counting Library (tiktoken-rs)
**Question**: Is tiktoken-rs production-ready for accurate OpenAI token counting? What are alternatives?
**Why**: FR-015 requires exact token counting for cost estimation. Inaccurate counting breaks trust in X-Nexus-Cost-Estimated header.
**Target**: Confirm library availability, verify accuracy ≥99%, identify fallback if needed.

#### RQ-002: Anthropic API Format
**Question**: What are the exact request/response schemas for Anthropic Messages API? How do roles and streaming differ from OpenAI?
**Why**: FR-004 requires bidirectional translation without data loss.
**Target**: Document message structure, role mappings, streaming SSE format, error responses.

#### RQ-003: Google AI API Format
**Question**: What are the request/response schemas for Google AI generateContent API? What are authentication requirements?
**Why**: FR-005 requires Google AI translation support.
**Target**: Document request structure, response format, authentication (API key vs. OAuth), streaming support.

#### RQ-004: Streaming Response Header Injection
**Question**: How do we inject headers into Axum SSE responses without buffering the entire stream?
**Why**: FR-017 requires X-Nexus-* headers on streaming responses with < 100ms latency penalty.
**Target**: Identify Axum SSE API for header injection, verify no buffering required.

#### RQ-005: HTTP Client Streaming Performance
**Question**: Does reqwest 0.12 support efficient streaming with low latency overhead?
**Why**: Streaming responses must relay chunks with < 100ms added latency (SC-009).
**Target**: Confirm reqwest streaming API, measure baseline latency.

#### RQ-006: Cost Estimation Pricing Models
**Question**: What are current pricing tiers for OpenAI GPT-4/GPT-3.5, Anthropic Claude, Google Gemini?
**Why**: X-Nexus-Cost-Estimated header must reflect accurate per-request costs.
**Target**: Document current pricing ($/1K tokens) for common models, identify update strategy.

### Research Outputs

All research findings will be documented in `research.md` with the structure:
- **Decision**: What was chosen
- **Rationale**: Why it was chosen
- **Alternatives Considered**: What else was evaluated
- **Implementation Notes**: Specific details for Phase 1

---

## Phase 1: Design Artifacts

Phase 1 generates the following artifacts after research completion:

### 1. data-model.md

Entities and relationships:
- **CloudBackendConfig** (extends BackendConfig)
- **CloudInferenceAgent** (implements InferenceAgent)
- **NexusTransparentHeaders** (standard header set)
- **ActionableErrorContext** (503 response structure)
- **APITranslator** (format conversion logic)

### 2. contracts/ Directory

API format examples:
- `openai-chat.json` - OpenAI chat completion (reference)
- `anthropic-messages.json` - Anthropic Messages API
- `google-generateContent.json` - Google AI format
- `nexus-headers.http` - X-Nexus-* header specs

### 3. quickstart.md

Developer guide covering:
- How to register a cloud backend in nexus.toml
- How to set up API keys via environment variables
- How to test cloud routing with curl examples
- How to interpret X-Nexus-* headers
- How to add a new cloud provider

---

## Phase 2: Task Generation (NOT in this plan)

After Phase 1 artifacts are complete, run `/speckit.tasks` to generate actionable task breakdown in `tasks.md`. Task generation is a separate workflow and not part of the plan command.

---

## Acceptance Criteria

This plan is complete when:

- [x] Technical Context filled with concrete values (no NEEDS CLARIFICATION)
- [x] Constitution Check evaluated with all gates passing
- [x] Project Structure defined with actual paths
- [ ] Research questions identified and documented
- [ ] Phase 0 research.md generated with all decisions
- [ ] Phase 1 data-model.md generated with entities
- [ ] Phase 1 contracts/ generated with format examples
- [ ] Phase 1 quickstart.md generated with developer guide
- [ ] Agent context updated with new technologies

---

## References

- **Feature Spec**: [spec.md](spec.md)
- **Constitution**: [.specify/memory/constitution.md](../../.specify/memory/constitution.md)
- **RFC-001**: Nexus Inference Interface (NII) - InferenceAgent trait foundation
- **Existing OpenAI Agent**: src/agent/openai.rs - pattern to follow
- **Response Pipeline**: src/api/completions.rs - header injection point

